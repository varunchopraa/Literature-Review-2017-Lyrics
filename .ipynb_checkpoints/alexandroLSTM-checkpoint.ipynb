{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating lyrics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "genresList = ['blues_lyrics', 'country_lyrics', 'disco_lyrics', 'hiphop_lyrics', 'metal_lyrics', 'pop_lyrics', 'reggae_lyrics', 'rock_lyrics']\n",
    "genreLyrics = dict()\n",
    "lyricStopped = {\n",
    "    'blues': list(),\n",
    "    'country': list(),\n",
    "    'disco': list(),\n",
    "    'hiphop': list(),\n",
    "    'metal': list(),\n",
    "    'pop': list(),\n",
    "    'reggae': list(),\n",
    "    'rock': list(),\n",
    "}\n",
    "\n",
    "header = ['filename', 'lyrics', 'genre']\n",
    "\n",
    "with open(f'lyrics.csv', 'w', newline = \"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "for genreName in genresList:\n",
    "    genre = sorted(os.listdir(f'../genres2/{genreName}'))\n",
    "    \n",
    "    for song in genre:\n",
    "#         print(genreName, song)\n",
    "        \n",
    "        if song == '.DS_Store':\n",
    "            continue\n",
    "            \n",
    "        path = f'../genres2/{genreName}/{song}'\n",
    "        songName = open(path, 'r')\n",
    "        lyric = songName.read()\n",
    "        \n",
    "        with open(f'lyrics.csv', 'a', newline = \"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([song, lyric, genreName.replace('_lyrics','')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(646,)\n",
      "(646,)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('lyrics.csv')\n",
    "X = dataset.iloc[:, 1].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = X[:]\n",
    "lyrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "lyric_encoded=le.fit_transform(lyrics.astype(str))\n",
    "lyric_encoded = np.reshape(lyric_encoded,(-1,1))\n",
    "lyric_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(646, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(646,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.row_stack(lyric_encoded)\n",
    "print(features.shape)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validating LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 484 samples, validate on 162 samples\n",
      "Epoch 1/20\n",
      "484/484 [==============================] - 1s 1ms/step - loss: 2.1620 - accuracy: 0.1488 - val_loss: 2.0706 - val_accuracy: 0.1543\n",
      "Epoch 2/20\n",
      "484/484 [==============================] - 0s 161us/step - loss: 2.1489 - accuracy: 0.1467 - val_loss: 2.0612 - val_accuracy: 0.1543\n",
      "Epoch 3/20\n",
      "484/484 [==============================] - 0s 158us/step - loss: 2.1253 - accuracy: 0.1467 - val_loss: 2.0590 - val_accuracy: 0.1543\n",
      "Epoch 4/20\n",
      "484/484 [==============================] - 0s 154us/step - loss: 2.1127 - accuracy: 0.1426 - val_loss: 2.0579 - val_accuracy: 0.1543\n",
      "Epoch 5/20\n",
      "484/484 [==============================] - 0s 162us/step - loss: 2.1016 - accuracy: 0.1632 - val_loss: 2.0559 - val_accuracy: 0.1543\n",
      "Epoch 6/20\n",
      "484/484 [==============================] - 0s 167us/step - loss: 2.0841 - accuracy: 0.1550 - val_loss: 2.0559 - val_accuracy: 0.1543\n",
      "Epoch 7/20\n",
      "484/484 [==============================] - 0s 163us/step - loss: 2.0684 - accuracy: 0.1612 - val_loss: 2.0534 - val_accuracy: 0.1543\n",
      "Epoch 8/20\n",
      "484/484 [==============================] - 0s 158us/step - loss: 2.0538 - accuracy: 0.1921 - val_loss: 2.0517 - val_accuracy: 0.1605\n",
      "Epoch 9/20\n",
      "484/484 [==============================] - 0s 155us/step - loss: 2.0176 - accuracy: 0.1983 - val_loss: 2.0524 - val_accuracy: 0.1914\n",
      "Epoch 10/20\n",
      "484/484 [==============================] - 0s 153us/step - loss: 1.9847 - accuracy: 0.2273 - val_loss: 2.0493 - val_accuracy: 0.2160\n",
      "Epoch 11/20\n",
      "484/484 [==============================] - 0s 153us/step - loss: 1.9737 - accuracy: 0.2459 - val_loss: 2.0438 - val_accuracy: 0.2037\n",
      "Epoch 12/20\n",
      "484/484 [==============================] - 0s 152us/step - loss: 1.8837 - accuracy: 0.3120 - val_loss: 2.0384 - val_accuracy: 0.2222\n",
      "Epoch 13/20\n",
      "484/484 [==============================] - 0s 154us/step - loss: 1.8402 - accuracy: 0.3533 - val_loss: 2.0347 - val_accuracy: 0.2160\n",
      "Epoch 14/20\n",
      "484/484 [==============================] - 0s 153us/step - loss: 1.7885 - accuracy: 0.3781 - val_loss: 2.0321 - val_accuracy: 0.2037\n",
      "Epoch 15/20\n",
      "484/484 [==============================] - 0s 161us/step - loss: 1.7044 - accuracy: 0.4587 - val_loss: 2.0280 - val_accuracy: 0.2037\n",
      "Epoch 16/20\n",
      "484/484 [==============================] - 0s 166us/step - loss: 1.6856 - accuracy: 0.4442 - val_loss: 2.0214 - val_accuracy: 0.2099\n",
      "Epoch 17/20\n",
      "484/484 [==============================] - 0s 160us/step - loss: 1.5887 - accuracy: 0.5083 - val_loss: 2.0120 - val_accuracy: 0.2037\n",
      "Epoch 18/20\n",
      "484/484 [==============================] - 0s 156us/step - loss: 1.4917 - accuracy: 0.5764 - val_loss: 2.0052 - val_accuracy: 0.1975\n",
      "Epoch 19/20\n",
      "484/484 [==============================] - 0s 154us/step - loss: 1.4420 - accuracy: 0.5930 - val_loss: 1.9964 - val_accuracy: 0.2160\n",
      "Epoch 20/20\n",
      "484/484 [==============================] - 0s 155us/step - loss: 1.2919 - accuracy: 0.6901 - val_loss: 1.9893 - val_accuracy: 0.2346\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense, GlobalMaxPooling1D, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = pd.read_csv('lyrics.csv')\n",
    "X = dataset.iloc[:, 1].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_enc = encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y_enc, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(3000, 100, input_length=1, trainable=True))\n",
    "model.add(LSTM(50, activation='sigmoid', return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_test, y_test),callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 53us/step\n",
      "Test set\n",
      "  Loss: 1.989\n",
      "  Accuracy: 0.235\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using trained LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i met a gin-soaked, bar-room queen in memphis\n",
      "she tried to take me upstairs for a ride\n",
      "she had to heave me right across shoulder\n",
      "'cause i just can't seem to drink you off my mind\n",
      "it's the honky tonk women\n",
      "gimme, gimme, gimme the honky tonk blues\n",
      "i laid a divorc√©e in new york city\n",
      "i had to put up some kind of a fight\n",
      "the lady then she covered me with roses\n",
      "she blew my nose and then she blew my mind\n",
      "it's the honky tonk women\n",
      "gimme, gimme, gimme the honky tonk blues\n",
      "it's the honky tonk women\n",
      "gimme, gimme, gimme the honky tonk blues\n",
      "it's the honky tonk women\n",
      "gimme, gimme, gimme the honky tonk blues\n"
     ]
    }
   ],
   "source": [
    "testFile = open('../genres2/rock_lyrics/rock.00031.txt', 'r')\n",
    "testLyrics = testFile.read().lower()\n",
    "print(testLyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04818559 0.04561532 0.04753147 0.09711573 0.05786032 0.04586843\n",
      "  0.22119156 0.43663153]] rock\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "predictedLabels = []\n",
    "tk = Tokenizer()\n",
    "from statistics import mode\n",
    "\n",
    "labels = ['blues', 'country', 'disco', 'hiphop', 'metal','pop', 'reggae', 'rock']\n",
    "\n",
    "tk.fit_on_texts(testLyrics)\n",
    "index_list = tk.texts_to_sequences([testLyrics])\n",
    "# print(index_list)\n",
    "padded = pad_sequences(index_list, maxlen=1)\n",
    "pred = model.predict(padded)\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
